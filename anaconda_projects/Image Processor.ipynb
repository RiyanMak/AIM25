{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "class ImageProcessor():\n",
    "    # Initializes standard image sizes: width and height = 64. Changing these values changes values in resize functions\n",
    "    def __init__(self, image_size=(64, 64)):\n",
    "        self.target_size = image_size\n",
    "\n",
    "    # open and read images from specified file path\n",
    "    def load_image(self, image_path):\n",
    "        # Loads an image from the given path and returns it as a numpy array\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"ERROR: Unable to read image at {image_path}\")\n",
    "        return image\n",
    "\n",
    "     # ensures that the input is not an empty array\n",
    "    def check_if_valid(self, image):\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            return False  # return False if not valid\n",
    "        return True  # return True if valid\n",
    "\n",
    "     # checks to see if image is grayscale\n",
    "    def convert_to_grayscale(self, image):\n",
    "        # RGB colored images usually have 3 dimensions (width, height, color)\n",
    "        # if the thrid dimesion of the tuple (represented by index of 2) has the color channel of RGB, then convert to grayscale\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        return image\n",
    "\n",
    "    #scales pixels to [0,1]\n",
    "    def normalize_image(self, image):\n",
    "      #converts to float32 in case data is integers\n",
    "      normalized_image = image.astype(np.float32) / 255.0\n",
    "      return normalized_image\n",
    "\n",
    "    # used to sharpen images using cv2 kernels (if data requires image sharpening)\n",
    "    def sharpen_image (self, image):\n",
    "      kerenel_sharpening = np.array([[-1,-1,-1],\n",
    "                                      [-1,9,-1],\n",
    "                                      [-1,-1,-1]])\n",
    "      sharpened_image = cv2.filter2D(image, -1, kerenel_sharpening)\n",
    "      return sharpened_image\n",
    "\n",
    "    # (1) resizes the image to target size using INTER_AREA interpolation, recommended when downscaling original image\n",
    "    def downscale_image(self, image):\n",
    "      return cv2.resize(image, self.target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # (2) resizes the image to target size using INTER_CUBIC interpolation, recommended when upscaling original image\n",
    "    def upscale_image(self, image):\n",
    "      return cv2.resize(image, self.target_size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # (3) resizes an image to target size while maintaining ratios (uses black padding to cover open space), prevents distortion.\n",
    "    # might need to change this function a little if image is not grayscaled\n",
    "    def resize_with_aspect_ratio(self, image, pad_color):\n",
    "      h, w = image.shape[:2]  #gets original dimensions of image\n",
    "      target_h, target_w = self.target_size  #gets target dimensions\n",
    "\n",
    "      aspect_original = w / h  #original aspect ratio\n",
    "      aspect_target = target_w / target_h  #target aspect ratio\n",
    "\n",
    "      # If the image already fits within the target size, no padding is required.\n",
    "      if h == target_h and w == target_w:\n",
    "          return image  # Return the image without changes if no padding is needed\n",
    "\n",
    "      # if our model does not need all images to be exact same size, padding not necessary\n",
    "      padded_image = np.zeros((target_h, target_w), dtype=np.uint8)  #creates blank image with target size (padding)\n",
    "      padded_image[:] = pad_color  #sets padded image color to black\n",
    "\n",
    "      #if original image is wider, recalculates height and sets width to max width (target width)\n",
    "      if aspect_original > aspect_target:\n",
    "          new_w = target_w\n",
    "          new_h = int(new_w / aspect_original)\n",
    "          #resizes image and uses either INTER_AREA or INTER_CUBIC depending on downscale or upscale\n",
    "          if new_h <= h:\n",
    "            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "          else:\n",
    "            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "          y_offset = (target_h - new_h) // 2  #calculates offset to center image on padded image (idk if we need this tbh)\n",
    "          padded_image[y_offset:y_offset + new_h, :] = resized  #places image on padded image\n",
    "\n",
    "      #if original image is taller, recalculates width and sets height to max height (target height)\n",
    "      else:\n",
    "          new_h = target_h\n",
    "          new_w = int(new_h * aspect_original)\n",
    "          if new_w <= w:\n",
    "            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "          else:\n",
    "            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "          x_offset = (target_w - new_w) // 2\n",
    "          padded_image[:, x_offset:x_offset + new_w] = resized\n",
    "\n",
    "      return padded_image  #returns original image\n",
    "\n",
    "    #cleans landmark data by handling missing values and outliers\n",
    "    #assumes all images have the same number of landmarks, so if not, we will have to change this function a bit\n",
    "    #if all images have the same number of landmarks, we still need to change a little to account for images that might be missing landmarks (NaN)\n",
    "    def clean_landmarks(self, landmarks_data):\n",
    "      if landmarks_data:\n",
    "        num_landmarks = len(landmarks_data[0]) #accesses first image and returns number of landmarks, assumes all images have the same # of landmarks\n",
    "      else:\n",
    "        return []  #functions stops here if landmark data is empty\n",
    "\n",
    "      #creates new list of landmark data by iterating through elements in original data\n",
    "      cleaned_landmarks = [list(landmark) for landmark in landmarks_data]\n",
    "\n",
    "      #replaces missing (None) values with mean\n",
    "      for i in range (num_landmarks):\n",
    "        values = [landmark[i] for landmark in cleaned_landmarks if landmark is not None]  #gets all valid landmark data\n",
    "        mean_val = np.mean(values)  #calculates mean\n",
    "        for j in range(len(cleaned_landmarks)): # Iterates through each landmark set in cleaned_landmarks\n",
    "            if cleaned_landmarks[j][i] is None:\n",
    "              cleaned_landmarks[j][i] = mean_val # If None, replace with the calculated mean\n",
    "\n",
    "      #Outlier remover\n",
    "      for i in range(num_landmarks):\n",
    "        values = [landmark[i] for landmark in cleaned_landmarks if landmark is not None]\n",
    "        if not values:\n",
    "          print(\"Warning: No valid data to calculate quartiles for a landmark. Returning unfiltered landmarks.\")\n",
    "          return cleaned_landmarks  # Returns the landmarks without filtering if there is no data to calculate quartiles\n",
    "        q1 = np.quantile(values, 0.25)  #calculates first quartile\n",
    "        q3 = np.quantile(values, 0.75)  #calculates third quartile\n",
    "        iqr = q3 - q1  #interquartile range\n",
    "        lower_bound = q1 - 1.5 * iqr  #any value below this is considered potential outlier\n",
    "        upper_bound = q3 + 1.5 * iqr  #any value above this is considered potential outlier\n",
    "\n",
    "        cleaned_landmarks_filtered = []  #create a new list to store cleaned landmarks\n",
    "        for landmark in cleaned_landmarks:  # iterate through each landmark\n",
    "          is_outlier = False\n",
    "          for j in range(num_landmarks):  #iterate through each coordinate of the landmark\n",
    "            if not (lower_bound <= landmark[j] <= upper_bound):  #check if the coordinate is outside the bounds\n",
    "              is_outlier = True  #if any coordinate is an outlier, mark the landmark as an outlier\n",
    "              break  #no need to check other coordinates for this landmark\n",
    "\n",
    "          #if the landmark is not an outlier, it is added to the filtered list\n",
    "          if not is_outlier:\n",
    "            cleaned_landmarks_filtered.append(landmark)  #add it to the filtered list\n",
    "\n",
    "      return cleaned_landmarks_filtered #return the filtered landmark data list at the end of the function\n",
    "\n",
    "      def clean_multiple_landmarks(self, landmarks_list):\n",
    "          cleaned_data = []\n",
    "          for landmarks_data in landmarks_list:\n",
    "              cleaned_data.append(self.clean_landmarks(landmarks_data))\n",
    "          return cleaned_data\n",
    "\n",
    "      #function to process a single image\n",
    "      def process_image(image_path, processor, landmarks_data=None):\n",
    "          image = processor.load_image(image_path)\n",
    "          if image is None:\n",
    "              return None, image_path #if image not loaded correctly, returns none along with image path to make error handling easier\n",
    "\n",
    "          #checks if image is a valid numpy array\n",
    "          if not processor.check_if_valid(image):\n",
    "              print(f\"Error: Image is not a numpy array: {image_path}\")\n",
    "              return None, image_path #if image not a numpy array, returns none along with image path\n",
    "\n",
    "          image = processor.convert_to_grayscale(image)\n",
    "          image = processor.normalize_image(image)\n",
    "          image = processor.resize_with_aspect_ratio(image)\n",
    "\n",
    "          if landmarks_data is not None: # Check if landmarks are provided\n",
    "              cleaned_landmarks = clean_landmarks(landmarks_data)\n",
    "              return image, image_path, cleaned_landmarks #Return cleaned landmarks\n",
    "          else:\n",
    "              return image, image_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
