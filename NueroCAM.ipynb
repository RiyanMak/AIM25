{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTxGrhiq1pg1V8+hEMifaO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiyanMak/AIM25/blob/Landmark-detection/NueroCAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup and Imports\n",
        "!pip install mediapipe opencv-python matplotlib\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files\n",
        "import io\n",
        "import time\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize MediaPipe Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "\n",
        "# Initialize Face Detection\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "\n",
        "# Define visualization settings\n",
        "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1, color=(0, 255, 0))\n",
        "\n",
        "# Helper Functions\n",
        "def detect_faces(image, face_detection):\n",
        "    \"\"\"\n",
        "    Detect faces in an image using MediaPipe Face Detection\n",
        "\n",
        "    Args:\n",
        "        image: Image in RGB format\n",
        "        face_detection: MediaPipe face detection instance\n",
        "\n",
        "    Returns:\n",
        "        List of detected face locations\n",
        "    \"\"\"\n",
        "    # Convert to RGB if necessary\n",
        "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
        "        rgb_image = image\n",
        "    else:\n",
        "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Process image to detect faces\n",
        "    results = face_detection.process(rgb_image)\n",
        "\n",
        "    faces = []\n",
        "    if results.detections:\n",
        "        for detection in results.detections:\n",
        "            # Get bounding box\n",
        "            bboxC = detection.location_data.relative_bounding_box\n",
        "            ih, iw, _ = image.shape\n",
        "            x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
        "                         int(bboxC.width * iw), int(bboxC.height * ih)\n",
        "            faces.append((x, y, w, h))\n",
        "\n",
        "    return faces\n",
        "\n",
        "\n",
        "def extract_facial_landmarks(image, face_mesh):\n",
        "    \"\"\"\n",
        "    Extract facial landmarks from an image using MediaPipe Face Mesh\n",
        "\n",
        "    Args:\n",
        "        image: Image in RGB format\n",
        "        face_mesh: MediaPipe face mesh instance\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping face indexes to NumPy arrays of landmark coordinates,\n",
        "        each of shape (num_landmarks, 3) where the columns represent (x, y, z)\n",
        "    \"\"\"\n",
        "    # Convert to RGB if necessary\n",
        "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
        "        rgb_image = image\n",
        "    else:\n",
        "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Process image to extract landmarks\n",
        "    results = face_mesh.process(rgb_image)\n",
        "\n",
        "    faces_landmarks = {}\n",
        "    if results.multi_face_landmarks:\n",
        "        for idx, face_landmarks in enumerate(results.multi_face_landmarks):\n",
        "            landmarks = []\n",
        "            for landmark in face_landmarks.landmark:\n",
        "                # Convert normalized coordinates to pixel coordinates\n",
        "                h, w, _ = image.shape\n",
        "                x = int(landmark.x * w)\n",
        "                y = int(landmark.y * h)\n",
        "                z = landmark.z  # Retain z as float\n",
        "                landmarks.append([x, y, z])\n",
        "            # Convert list to a NumPy array\n",
        "            landmarks_array = np.array(landmarks)\n",
        "            faces_landmarks[idx] = landmarks_array\n",
        "\n",
        "    return faces_landmarks\n",
        "\n",
        "\n",
        "def visualize_landmarks(image, faces_landmarks, connections=None):\n",
        "    \"\"\"\n",
        "    Draw facial landmarks on an image\n",
        "\n",
        "    Args:\n",
        "        image: Image to draw on\n",
        "        faces_landmarks: Dictionary of face indexes with landmark coordinates\n",
        "        connections: Optional list of landmark connections to draw\n",
        "\n",
        "    Returns:\n",
        "        Image with landmarks drawn\n",
        "    \"\"\"\n",
        "    # Make a copy to avoid modifying the original image\n",
        "    vis_image = image.copy()\n",
        "\n",
        "    for face_idx, landmarks in faces_landmarks.items():\n",
        "        # Draw each landmark as a circle\n",
        "        for i, (x, y, _) in enumerate(landmarks):\n",
        "            cv2.circle(vis_image, (x, y), 1, (0, 255, 0), -1)\n",
        "\n",
        "        # If connections are provided, draw lines between landmarks\n",
        "        if connections:\n",
        "            for connection in connections:\n",
        "                start_idx, end_idx = connection\n",
        "                if start_idx < len(landmarks) and end_idx < len(landmarks):\n",
        "                    start_point = landmarks[start_idx][:2]  # (x, y) only\n",
        "                    end_point = landmarks[end_idx][:2]  # (x, y) only\n",
        "                    cv2.line(vis_image, start_point, end_point, (255, 0, 0), 1)\n",
        "\n",
        "    return vis_image\n",
        "\n",
        "def visualize_face_mesh(image, multi_face_landmarks):\n",
        "    \"\"\"\n",
        "    Draw face mesh on an image using MediaPipe's drawing utilities\n",
        "\n",
        "    Args:\n",
        "        image: Image to draw on\n",
        "        multi_face_landmarks: MediaPipe face landmarks\n",
        "\n",
        "    Returns:\n",
        "        Image with face mesh drawn\n",
        "    \"\"\"\n",
        "    # Make a copy to avoid modifying the original image\n",
        "    vis_image = image.copy()\n",
        "\n",
        "    # Draw the face mesh on the image\n",
        "    for face_landmarks in multi_face_landmarks:\n",
        "        mp_drawing.draw_landmarks(\n",
        "            image=vis_image,\n",
        "            landmark_list=face_landmarks,\n",
        "            connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "            landmark_drawing_spec=None,\n",
        "            connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
        "\n",
        "        # Draw the face contours\n",
        "        mp_drawing.draw_landmarks(\n",
        "            image=vis_image,\n",
        "            landmark_list=face_landmarks,\n",
        "            connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "            landmark_drawing_spec=None,\n",
        "            connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())\n",
        "\n",
        "    return vis_image\n",
        "\n",
        "\n",
        "\n",
        "# Function to extract specific facial features (for Week 3)\n",
        "def extract_facial_features(landmarks):\n",
        "    \"\"\"\n",
        "    Extract key facial features from landmarks that may be relevant for neurological disorder detection\n",
        "    This is a placeholder for Week 3's feature extraction task\n",
        "\n",
        "    Args:\n",
        "        landmarks: List of landmark coordinates (x, y, z)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of extracted features\n",
        "    \"\"\"\n",
        "    # Eye aspect ratio (measure of eye openness)\n",
        "    # Left eye indices (simplified)\n",
        "    left_eye_top = landmarks[159]\n",
        "    left_eye_bottom = landmarks[145]\n",
        "    left_eye_left = landmarks[33]\n",
        "    left_eye_right = landmarks[133]\n",
        "\n",
        "    # Right eye indices (simplified)\n",
        "    right_eye_top = landmarks[386]\n",
        "    right_eye_bottom = landmarks[374]\n",
        "    right_eye_left = landmarks[362]\n",
        "    right_eye_right = landmarks[263]\n",
        "\n",
        "    # Mouth indices (simplified)\n",
        "    mouth_left = landmarks[61]\n",
        "    mouth_right = landmarks[291]\n",
        "    mouth_top = landmarks[0]\n",
        "    mouth_bottom = landmarks[17]\n",
        "\n",
        "    # Calculate eye aspect ratios\n",
        "    def calculate_distance(point1, point2):\n",
        "        return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n",
        "\n",
        "    left_eye_height = calculate_distance(left_eye_top, left_eye_bottom)\n",
        "    left_eye_width = calculate_distance(left_eye_left, left_eye_right)\n",
        "    left_eye_ratio = left_eye_height / left_eye_width if left_eye_width > 0 else 0\n",
        "\n",
        "    right_eye_height = calculate_distance(right_eye_top, right_eye_bottom)\n",
        "    right_eye_width = calculate_distance(right_eye_left, right_eye_right)\n",
        "    right_eye_ratio = right_eye_height / right_eye_width if right_eye_width > 0 else 0\n",
        "\n",
        "    # Mouth aspect ratio\n",
        "    mouth_height = calculate_distance(mouth_top, mouth_bottom)\n",
        "    mouth_width = calculate_distance(mouth_left, mouth_right)\n",
        "    mouth_ratio = mouth_height / mouth_width if mouth_width > 0 else 0\n",
        "\n",
        "    # Return extracted features\n",
        "    features = {\n",
        "        'left_eye_ratio': left_eye_ratio,\n",
        "        'right_eye_ratio': right_eye_ratio,\n",
        "        'eye_symmetry': abs(left_eye_ratio - right_eye_ratio),\n",
        "        'mouth_ratio': mouth_ratio\n",
        "    }\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Load test image\n",
        "    image_path = \"test_image.jpg\"  # Change to your test image path\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(\"Error: Image not found.\")\n",
        "        return\n",
        "\n",
        "    # Initialize MediaPipe models\n",
        "    face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)\n",
        "    face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = detect_faces(image, face_detection)\n",
        "    print(f\"Detected {len(faces)} face(s).\")\n",
        "\n",
        "    # Extract landmarks\n",
        "    landmarks = extract_facial_landmarks(image, face_mesh)\n",
        "    if not landmarks:\n",
        "        print(\"No facial landmarks detected.\")\n",
        "        return\n",
        "\n",
        "    # Print landmark shape for verification\n",
        "    for idx, lm in landmarks.items():\n",
        "        print(f\"Face {idx}: Landmarks shape {lm.shape}\")\n",
        "\n",
        "    # Visualize landmarks\n",
        "    vis_image = visualize_landmarks(image, landmarks)\n",
        "    cv2.imshow(\"Landmarks\", vis_image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "tQPQWS0SMXP1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}