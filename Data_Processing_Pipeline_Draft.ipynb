{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiyanMak/AIM25/blob/preprocessing-pipeline/Data_Processing_Pipeline_Draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from os import listdir"
      ],
      "metadata": {
        "id": "dEgCaoqk9eBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I made 3 different resizing methods, not sure which one we should use. Maybe resizing while maintaining aspect ratio\n",
        "is better in case the images aren't perfectly squares and we want target size to be a square. The resize function also\n",
        "uses the same interpolation methods as the other two functions.\n",
        "All functions take image as numpy array."
      ],
      "metadata": {
        "id": "YbLG5nZ2dNqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageProcessor():\n",
        "    # Initializes standard image sizes: width and height = 64. Changing these values changes values in resize functions\n",
        "    def __init__(self, image_size=(64, 64)):\n",
        "        self.target_size = image_size\n",
        "\n",
        "    # open and read images from specified file path\n",
        "    def load_image(self, image_path):\n",
        "        # Loads an image from the given path and returns it as a numpy array\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\"ERROR: Unable to read image at {image_path}\")\n",
        "        return image\n",
        "\n",
        "     # ensures that the input is not an empty array\n",
        "    def check_if_valid(self, image):\n",
        "        if not isinstance(image, np.ndarray):\n",
        "            return False  # return False if not valid\n",
        "        return True  # return True if valid\n",
        "\n",
        "     # checks to see if image is grayscale\n",
        "    def convert_to_grayscale(self, image):\n",
        "        # RGB colored images usually have 3 dimensions (width, height, color)\n",
        "        # if the thrid dimesion of the tuple (represented by index of 2) has the color channel of RGB, then convert to grayscale\n",
        "        if len(image.shape) == 3 and image.shape[2] == 3:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        return image\n",
        "\n",
        "    #scales pixels to [0,1]\n",
        "    def normalize_image(self, image):\n",
        "      #converts to float32 in case data is integers\n",
        "      normalized_image = image.astype(np.float32) / 255.0\n",
        "      return normalized_image\n",
        "\n",
        "    # used to sharpen images using cv2 kernels (if data requires image sharpening)\n",
        "    def sharpen_image (self, image):\n",
        "      kerenel_sharpening = np.array([[-1,-1,-1],\n",
        "                                      [-1,9,-1],\n",
        "                                      [-1,-1,-1]])\n",
        "      sharpened_image = cv2.filter2D(image, -1, kerenel_sharpening)\n",
        "      return sharpened_image\n",
        "\n",
        "    # (1) resizes the image to target size using INTER_AREA interpolation, recommended when downscaling original image\n",
        "    def downscale_image(self, image):\n",
        "      return cv2.resize(image, self.target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # (2) resizes the image to target size using INTER_CUBIC interpolation, recommended when upscaling original image\n",
        "    def upscale_image(self, image):\n",
        "      return cv2.resize(image, self.target_size, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # (3) resizes an image to target size while maintaining ratios (uses black padding to cover open space), prevents distortion.\n",
        "    # might need to change this function a little if image is not grayscaled\n",
        "    def resize_with_aspect_ratio(self, image, pad_color):\n",
        "      h, w = image.shape[:2]  #gets original dimensions of image\n",
        "      target_h, target_w = self.target_size  #gets target dimensions\n",
        "\n",
        "      aspect_original = w / h  #original aspect ratio\n",
        "      aspect_target = target_w / target_h  #target aspect ratio\n",
        "\n",
        "      # If the image already fits within the target size, no padding is required.\n",
        "      if h == target_h and w == target_w:\n",
        "          return image  # Return the image without changes if no padding is needed\n",
        "\n",
        "      # if our model does not need all images to be exact same size, padding not necessary\n",
        "      padded_image = np.zeros((target_h, target_w), dtype=np.uint8)  #creates blank image with target size (padding)\n",
        "      padded_image[:] = pad_color  #sets padded image color to black\n",
        "\n",
        "      #if original image is wider, recalculates height and sets width to max width (target width)\n",
        "      if aspect_original > aspect_target:\n",
        "          new_w = target_w\n",
        "          new_h = int(new_w / aspect_original)\n",
        "          #resizes image and uses either INTER_AREA or INTER_CUBIC depending on downscale or upscale\n",
        "          if new_h <= h:\n",
        "            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "          else:\n",
        "            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "          y_offset = (target_h - new_h) // 2  #calculates offset to center image on padded image (idk if we need this tbh)\n",
        "          padded_image[y_offset:y_offset + new_h, :] = resized  #places image on padded image\n",
        "\n",
        "      #if original image is taller, recalculates width and sets height to max height (target height)\n",
        "      else:\n",
        "          new_h = target_h\n",
        "          new_w = int(new_h * aspect_original)\n",
        "          if new_w <= w:\n",
        "            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "          else:\n",
        "            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "          x_offset = (target_w - new_w) // 2\n",
        "          padded_image[:, x_offset:x_offset + new_w] = resized\n",
        "\n",
        "      return padded_image  #returns original image\n",
        "\n",
        "\n",
        "    def clean_landmarks(self, landmarks_array):\n",
        "      if landmarks_array is None or len(landmarks_array) == 0:\n",
        "        return np.array([])\n",
        "      cleaned_landmarks = landmarks_array.tolist()\n",
        "      num_landmarks = len(cleaned_landmarks[0])\n",
        "      all_values = [landmark[i] for landmark in cleaned_landmarks for i in range(num_landmarks) if landmark[i] is not None]\n",
        "      if all_values:\n",
        "        mean_val = np.mean(all_values)\n",
        "        for j in range(len(cleaned_landmarks)):\n",
        "          for i in range(num_landmarks):\n",
        "            if cleaned_landmarks[j][i] is None:\n",
        "              cleaned_landmarks[j][i] = mean_val\n",
        "      else:\n",
        "        print(\"Warning: No valid data for mean calculation, skipping mean replacement\")\n",
        "      all_values = [landmark[i] for landmark in cleaned_landmarks for i in range(num_landmarks) if landmark[i] is not None]\n",
        "      if all_values:\n",
        "        q1 = np.quantile(all_values, 0.25)\n",
        "        q3 = np.quantile(all_values, 0.75)\n",
        "        iqr = q3 - q1\n",
        "        lower_bound = q1 - 1.5 * iqr\n",
        "        upper_bound = q3 + 1.5 * iqr\n",
        "        cleaned_landmarks_filtered = []\n",
        "        for landmark in cleaned_landmarks:\n",
        "          if all(lower_bound <= landmark[i] <= upper_bound for i in range(num_landmarks)):\n",
        "            cleaned_landmarks_filtered.append(landmark)\n",
        "        return np.array(cleaned_landmarks_filtered)\n",
        "      else:\n",
        "        print(\"Warning: No valid data for outlier detection, returning unfiltered landmarks\")\n",
        "        return np.array(cleaned_landmarks)\n",
        "\n",
        "    def process_landmark_dictionary_combined(self, landmarks_dict):\n",
        "        all_arrays = list(landmarks_dict.values())\n",
        "        combined_array = np.concatenate(all_arrays, axis=0) if all_arrays else np.array([])\n",
        "        cleaned_combined_array = self.clean_landmarks(combined_array)\n",
        "\n",
        "        cleaned_landmarks_dict = {}\n",
        "        if cleaned_combined_array.size > 0:\n",
        "            start_idx = 0\n",
        "            for image_path, landmarks_array in landmarks_dict.items():\n",
        "                num_rows = landmarks_array.shape[0]\n",
        "                end_idx = start_idx + num_rows\n",
        "                cleaned_landmarks_dict[image_path] = cleaned_combined_array[start_idx:end_idx]\n",
        "                start_idx = end_idx\n",
        "        else:\n",
        "            for image_path in landmarks_dict:\n",
        "                cleaned_landmarks_dict[image_path] = np.array([])\n",
        "        return cleaned_landmarks_dict\n",
        "\n",
        "   #function to process a single image\n",
        "      #returns a tuple: (processed_image, image_path) or None if image loading failed\n",
        "    def process_image(self, image_path):\n",
        "       image = self.load_image(image_path)\n",
        "       if image is None:\n",
        "          return None, image_path\n",
        "       if not self.check_if_valid(image):\n",
        "          print(f\"Error: Image is not a numpy array: {image_path}\")\n",
        "          return None, image_path\n",
        "       image = self.convert_to_grayscale(image)\n",
        "       image = self.normalize_image(image)\n",
        "       image = self.sharpen_image(image)\n",
        "       image = self.resize_with_aspect_ratio(image)\n",
        "       return image, image_path\n",
        "\n",
        "    #function to process images in a file\n",
        "    #takes landmarks as a dictionary where keys are image filenames and values are corresponding landmark data\n",
        "    #returns a list of tuples, where each tuple contains (processed_image, image_path, cleaned_landmarks(if applicable))\n",
        "    def process_multiple_image(self, folder_path, landmarks_dict=None):\n",
        "      results = []\n",
        "      for filename in os.listdir(folder_path):\n",
        "          image_path = os.path.join(folder_path, filename)\n",
        "          processed_result = self.process_image(image_path)\n",
        "\n",
        "          if processed_result[0] is not None:\n",
        "              results.append(processed_result)\n",
        "\n",
        "      if landmarks_dict is not None:\n",
        "          cleaned_landmarks_dict = self.process_landmark_dictionary_combined(landmarks_dict)\n",
        "          for i, result in enumerate(results):\n",
        "              image_name = os.path.basename(result[1])\n",
        "              if cleaned_landmarks_dict.get(image_name) is not None:\n",
        "                  results[i] = (result[0], result[1], cleaned_landmarks_dict[image_name])\n",
        "      return results"
      ],
      "metadata": {
        "id": "0iI2JavxxzdW"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}
