{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiyanMak/AIM25/blob/preprocessing-pipeline/Data_Processing_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from os import listdir\n",
        "!pip install mediapipe\n",
        "import mediapipe as mp"
      ],
      "metadata": {
        "id": "dEgCaoqk9eBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "487b4b17-ffdf-4d38-d834-ad3e792a8c7d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.6)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I made 3 different resizing methods, not sure which one we should use. Maybe resizing while maintaining aspect ratio\n",
        "is better in case the images aren't perfectly squares and we want target size to be a square. The resize function also\n",
        "uses the same interpolation methods as the other two functions.\n",
        "All functions take image as numpy array."
      ],
      "metadata": {
        "id": "YbLG5nZ2dNqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuc-0rSZBsjf",
        "outputId": "1580bdfe-fbc5-460c-94e6-4e58685cc32a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageProcessor():\n",
        "    # Initializes standard image sizes: width and height = 64. Changing these values changes values in resize functions\n",
        "    def __init__(self, image_size=(64, 64)):\n",
        "        self.target_size = image_size\n",
        "\n",
        "    # open and read images from specified file path\n",
        "    def load_image(self, image_path):\n",
        "        # Loads an image from the given path and returns it as a numpy array\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\"ERROR: Unable to read image at {image_path}\")\n",
        "        return image\n",
        "\n",
        "     # ensures that the input is not an empty array\n",
        "    def check_if_valid(self, image):\n",
        "        if not isinstance(image, np.ndarray):\n",
        "            return False  # return False if not valid\n",
        "        return True  # return True if valid\n",
        "\n",
        "     # checks to see if image is grayscale\n",
        "    def convert_to_grayscale(self, image):\n",
        "        # RGB colored images usually have 3 dimensions (width, height, color)\n",
        "        # if the thrid dimesion of the tuple (represented by index of 2) has the color channel of RGB, then convert to grayscale\n",
        "        if len(image.shape) == 3 and image.shape[2] == 3:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        return image\n",
        "\n",
        "    #scales pixels to [0,1]\n",
        "    def normalize_image(self, image):\n",
        "      #converts to float32 in case data is integers\n",
        "      normalized_image = image.astype(np.float32) / 255.0\n",
        "      return normalized_image\n",
        "\n",
        "    # used to sharpen images using cv2 kernels (if data requires image sharpening)\n",
        "    def sharpen_image (self, image):\n",
        "      kerenel_sharpening = np.array([[-1,-1,-1],\n",
        "                                      [-1,9,-1],\n",
        "                                      [-1,-1,-1]])\n",
        "      sharpened_image = cv2.filter2D(image, -1, kerenel_sharpening)\n",
        "      return sharpened_image\n",
        "\n",
        "    # (1) resizes the image to target size using INTER_AREA interpolation, recommended when downscaling original image\n",
        "    def downscale_image(self, image):\n",
        "      return cv2.resize(image, self.target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # (2) resizes the image to target size using INTER_CUBIC interpolation, recommended when upscaling original image\n",
        "    def upscale_image(self, image):\n",
        "      return cv2.resize(image, self.target_size, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # (3) resizes an image to target size while maintaining ratios (uses black padding to cover open space), prevents distortion.\n",
        "    # might need to change this function a little if image is not grayscaled\n",
        "    def resize_with_aspect_ratio(self, image, pad_color):\n",
        "      h, w = image.shape[:2]  #gets original dimensions of image\n",
        "      target_h, target_w = self.target_size  #gets target dimensions\n",
        "\n",
        "      aspect_original = w / h  #original aspect ratio\n",
        "      aspect_target = target_w / target_h  #target aspect ratio\n",
        "\n",
        "      # If the image already fits within the target size, no padding is required.\n",
        "      if h == target_h and w == target_w:\n",
        "          return image  # Return the image without changes if no padding is needed\n",
        "\n",
        "      # if our model does not need all images to be exact same size, padding not necessary\n",
        "      padded_image = np.zeros((target_h, target_w), dtype=np.uint8)  #creates blank image with target size (padding)\n",
        "      padded_image[:] = pad_color  #sets padded image color to black\n",
        "\n",
        "      #if original image is wider, recalculates height and sets width to max width (target width)\n",
        "      if aspect_original > aspect_target:\n",
        "          new_w = target_w\n",
        "          new_h = int(new_w / aspect_original)\n",
        "          #resizes image and uses either INTER_AREA or INTER_CUBIC depending on downscale or upscale\n",
        "          if new_h <= h:\n",
        "            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "          else:\n",
        "            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "          y_offset = (target_h - new_h) // 2  #calculates offset to center image on padded image (idk if we need this tbh)\n",
        "          padded_image[y_offset:y_offset + new_h, :] = resized  #places image on padded image\n",
        "\n",
        "      #if original image is taller, recalculates width and sets height to max height (target height)\n",
        "      else:\n",
        "          new_h = target_h\n",
        "          new_w = int(new_h * aspect_original)\n",
        "          if new_w <= w:\n",
        "            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "          else:\n",
        "            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "          x_offset = (target_w - new_w) // 2\n",
        "          padded_image[:, x_offset:x_offset + new_w] = resized\n",
        "\n",
        "      return padded_image  #returns original image\n",
        "\n",
        "\n",
        "    def clean_landmarks(self, landmarks_array):\n",
        "      if landmarks_array is None or len(landmarks_array) == 0:\n",
        "        return np.array([])\n",
        "      cleaned_landmarks = landmarks_array.tolist()\n",
        "      num_landmarks = len(cleaned_landmarks[0])\n",
        "      all_values = [landmark[i] for landmark in cleaned_landmarks for i in range(num_landmarks) if landmark[i] is not None]\n",
        "      if all_values:\n",
        "        mean_val = np.mean(all_values)\n",
        "        for j in range(len(cleaned_landmarks)):\n",
        "          for i in range(num_landmarks):\n",
        "            if cleaned_landmarks[j][i] is None:\n",
        "              cleaned_landmarks[j][i] = mean_val\n",
        "      else:\n",
        "        print(\"Warning: No valid data for mean calculation, skipping mean replacement\")\n",
        "      all_values = [landmark[i] for landmark in cleaned_landmarks for i in range(num_landmarks) if landmark[i] is not None]\n",
        "      if all_values:\n",
        "        q1 = np.quantile(all_values, 0.25)\n",
        "        q3 = np.quantile(all_values, 0.75)\n",
        "        iqr = q3 - q1\n",
        "        lower_bound = q1 - 1.5 * iqr\n",
        "        upper_bound = q3 + 1.5 * iqr\n",
        "        cleaned_landmarks_filtered = []\n",
        "        for landmark in cleaned_landmarks:\n",
        "          if all(lower_bound <= landmark[i] <= upper_bound for i in range(num_landmarks)):\n",
        "            cleaned_landmarks_filtered.append(landmark)\n",
        "        return np.array(cleaned_landmarks_filtered)\n",
        "      else:\n",
        "        print(\"Warning: No valid data for outlier detection, returning unfiltered landmarks\")\n",
        "        return np.array(cleaned_landmarks)\n",
        "\n",
        "\n",
        "        def process_image(self, image_path): #added this needed function.\n",
        "          image = self.load_image(image_path)\n",
        "          if image is None:\n",
        "              return (None, image_path, None)\n",
        "\n",
        "          image = self.convert_to_grayscale(image)\n",
        "          image = self.resize_with_aspect_ratio(image, 0)\n",
        "          image = self.normalize_image(image)\n",
        "\n",
        "          return (image, image_path, None)\n",
        "\n",
        "\n",
        "    #function to process images in a file\n",
        "    #takes landmarks as a dictionary where keys are image filenames and values are corresponding landmark data\n",
        "    #returns a list of tuples, where each tuple contains (processed_image, image_path, cleaned_landmarks(if applicable))\n",
        "    def process_multiple_image(self, folder_path, landmarks_dict=None):\n",
        "      results = []\n",
        "      for filename in os.listdir(folder_path):\n",
        "          image_path = os.path.join(folder_path, filename)\n",
        "          processed_result = self.process_image(image_path)\n",
        "\n",
        "          if processed_result[0] is not None:\n",
        "              results.append(processed_result)\n",
        "\n",
        "      if landmarks_dict is not None:\n",
        "          cleaned_landmarks_dict = self.process_landmark_dictionary_combined(landmarks_dict)\n",
        "          for i, result in enumerate(results):\n",
        "              image_name = os.path.basename(result[1])\n",
        "              if cleaned_landmarks_dict.get(image_name) is not None:\n",
        "                  results[i] = (result[0], result[1], cleaned_landmarks_dict[image_name])\n",
        "      return results\n",
        "\n",
        "    mp_face_mesh = mp.solutions.face_mesh\n",
        "    mp_face_detection = mp.solutions.face_detection\n",
        "    mp_drawing = mp.solutions.drawing_utils\n",
        "    mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "    def process_images_with_landmarks_in_folder(self, folder_path):\n",
        "        # Used to store the landmarks\n",
        "        all_landmarks = {}\n",
        "\n",
        "        # Get all image paths (both .jpg and .png)\n",
        "        image_paths = glob.glob(os.path.join(folder_path, \"*.jpg\")) + glob.glob(os.path.join(folder_path, \"*.png\"))\n",
        "\n",
        "        # Loop through each image in the folder\n",
        "        for image_path in image_paths:\n",
        "            processor = ImageProcessor(image_size=(128, 128))\n",
        "\n",
        "            # Get each image in the folder\n",
        "            image = processor.load_image(image_path)\n",
        "            if image is None:\n",
        "                print(f\"Error: Could not load image {image_path}\")\n",
        "                all_landmarks[image_path] = None\n",
        "                continue\n",
        "\n",
        "            # Add mesh to the faces\n",
        "            face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)\n",
        "            face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
        "\n",
        "            # Detect the face so we can get the landmarks\n",
        "            faces = detect_faces(image, face_detection)\n",
        "            if not faces:\n",
        "                print(f\"No faces detected in image: {image_path}\")\n",
        "                all_landmarks[image_path] = None\n",
        "                continue\n",
        "\n",
        "            # Extract landmarks\n",
        "            landmarks_dict = extract_facial_landmarks(image, face_mesh)\n",
        "            if not landmarks_dict:\n",
        "                print(f\"No facial landmarks detected in image: {image_path}\")\n",
        "                all_landmarks[image_path] = None\n",
        "                continue\n",
        "\n",
        "            # Process landmarks\n",
        "            processed_landmarks_dict = {}\n",
        "            for face_idx, landmarks in landmarks_dict.items():\n",
        "                processed_landmarks = processor.process_landmarks(landmarks)\n",
        "                processed_landmarks_dict[face_idx] = processed_landmarks\n",
        "\n",
        "            # Store the processed landmarks in the dictionary\n",
        "            all_landmarks[image_path] = processed_landmarks_dict\n",
        "\n",
        "        return all_landmarks\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    path = '/content/drive/MyDrive/RAFD Test Image Folder'\n",
        "    #stored the return landmarks\n",
        "    processor = ImageProcessor()\n",
        "    landmarks_by_image = processor.process_images_with_landmarks_in_folder(path)\n",
        "\n",
        "    processor.process_multiple_image(path, landmarks_by_image)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0iI2JavxxzdW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "9524450a-eba2-4f4f-cdff-2d80de290df4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'detect_faces' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-aaddce572f41>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;31m#stored the return landmarks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mlandmarks_by_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_images_with_landmarks_in_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_multiple_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks_by_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-aaddce572f41>\u001b[0m in \u001b[0;36mprocess_images_with_landmarks_in_folder\u001b[0;34m(self, folder_path)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;31m# Detect the face so we can get the landmarks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_detection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No faces detected in image: {image_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'detect_faces' is not defined"
          ]
        }
      ]
    }
  ]
}